\documentclass[12pt, titlepage]{article}

% Packages

\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{float}
\usepackage{hyperref}
\usepackage{indentfirst}
\usepackage[usenames, dvipsnames]{color}
\usepackage{tikz}

% Colour Scheme

\hypersetup{
    colorlinks,
    citecolor=blue,
    filecolor=ForestGreen,
    linkcolor=MidnightBlue,
    urlcolor=blue
}

% Custom Commands

% Title Page Elements

\title{SE 3XA3: Test Plan\\Rogue Reborn}

\author{Group \#6, Team Rogue++\\\\
	\begin{tabular} {l r}
		Ian Prins & prinsij \\
		Mikhail Andrenkov & andrem5 \\
		Or Almog & almogo
	\end{tabular}
}

\date{Due Monday, October 31\textsuperscript{th}, 2016}

\input{../Comments}

\begin{document}

\maketitle

% Report outline

\pagenumbering{roman}
\tableofcontents
\listoftables
\listoffigures

% Revision Table

\begin{table}[bp]
	\caption{\bf Revision History}
	\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
		\toprule {\bf Date} & {\bf Version} & {\bf Notes}\\
		\midrule
		10/21/16 & 0.0 & Initial Setup\\
		10/24/16 & 0.1 & Added Unit Testing and Usability Survey \\
		10/24/16 & 0.2 & Added Most of Section 2 \\
		10/24/16 & 0.3 & Added Section 1 \\
		\bottomrule
	\end{tabularx}
\end{table}

\newpage

% Report Content

\pagenumbering{arabic}

\section{General Information}

	\subsection{Purpose}
		The purpose of this document is to explore the verification process that will be applied to the Rogue Reborn project.  After reviewing the document, the reader should understand the strategy, focus, and motivation behind the efforts of the Rogue++ testing team.   

	\subsection{Scope}
		This report will encompass all technical aspects of the testing environment and implementation plan, as well as other elements in the domain of team coordination and project deadlines.  The document will also strive to be comprehensive by providing context behind critical decisions, motivating the inclusion of particular features by referring to the existing \textit{Rogue} implementation, and offering a large variety of tests for various purposes and hierarchical units.  Aside from the implementation, the report will also discuss a relevant component from the requirements elicitation process.

	\subsection{Acronyms, Abbreviations, and Symbols}
		
		\begin{table}[H]
			\centering
			\caption{\textbf{Table of Abbreviations and Acronyms}}
			\label{TableAbbreviations}
			\bigskip
			\begin{tabularx}{\textwidth}{p{3cm}X}
				\toprule
				\textbf{Abbreviation} & \textbf{Definition} \\
				\midrule
				PoC & Proof of Concept\\
				\bottomrule
			\end{tabularx}
		\end{table}

		\begin{table}[H]
			\centering
			\caption{\textbf{Table of Definitions}}
			\label{TableDefinitions}
			\bigskip
			\begin{tabularx}{\textwidth}{p{3cm}X}
				\toprule
				\textbf{Term} & \textbf{Definition}\\
				\midrule
				\textbf{Boost} & C++ utility library that includes a comprehensive unit testing framework\\
				\textbf{Libtcod} & Graphics library that specializes in emulating a roguelike experience\\
				\textbf{Permadeath} & Feature of roguelike games whereby a character death will end the game\\
				\textbf{Roguelike} & Genre of video games characterized by ASCII graphics, procedurally-generated levels, and permadeath\\
				\bottomrule
			\end{tabularx}
		\end{table}	

	\subsection{Overview of Document}
		The early sections of the report will describe the testing environment and the logistic components of the Rogue Reborn testing effort, including the schedule and work allocation.  Next, a suite of tests will be discussed with respect to the functional requirements, nonfunctional requirements, and proof of concept demonstration.  Upon discussing the relevance of this project to the original \textit{Rogue}, a variety of unit tests will be given followed by a sample usability survey to guage the interest and opinion of the Rogue Reborn game.  A breakdown of the sections is listed below:

		\begin{itemize}
			\item \S1 - Brief overview of the report contents
			\item \S2 - Project logistics and the software testing environment
			\item \S3 - Description of system-level integration tests (based on requirements)
			\item \S4 - Explanation of test plans that were inspired by the PoC demonstration
			\item \S5 - Comparison of the existing \textit{Rogue} to the current project in the context of testing
			\item \S6 - Outline of the module-level unit tests 
			\item \S7 - Appendix for symbolic parameters and the aforementioned usability survey
		\end{itemize}

\newpage
\section{Plan}
		
	\subsection{Software Description}

	Initially, the plan for testing involved the usage of a pre-made testing system called Boost. Boost has industry renown and is very well documented. The drawback to using such a profound system is exactly its advantage - it is heavy, globally encompassing, and requires a lot of work to use properly. The Boost library is suitable for projects spanning years, with dedicated testing teams. This is not the present situation. With hardly over a month until the completion of the project, starting to use Boost would be most unwise.\\

	Instead, an alternative solution has been proposed and implemented. Native test cases can be written in C++ to do exactly that which is required. The details of this implementation will be explained in the parts to follow.

	\subsection{Test Team}

	All members of the team will take part in the testing procedure. While Mikhail was given the title of project manager, and Ian C++ expert, Ori was assigned the role of testing expert. Testing will be monitored by Ori, but of course every member of the team will contribute to the testing facilities. It would be desirable for the team member who wrote class $C$ to write the unit tests for this class. Due to the dependency-tree-like structure of the project's design, there will be cases where a unit test for one class encompasses a partial system test for another one. This can be extrapolated from the class inheritance diagram.

	\subsection{Automated Testing Approach}

	We have made a very large attempt at automating whatever we could for this project. In the real world, any task that \textit{can} be automated, is automated. The steps we have taken are as follows:

	\begin{itemize}
		\item Set up a GitLab pipeline for the project. The pipeline is programmed to run a series of commands on an external VPS whenever a push is made to the git repository. Each run is documented and its history may be accessed.
		\item Write a special makefile that outputs 2 executables: the first being the actual project, and the second the project's tests. The details will be delved into in the following sub-section.
		\item The team's primary method of communication is Slack, a cross-platform, programmer-friendly chat interface. We hooked up the GitLab project repository to the Slack channel such that whenever a push is made or an issue addressed, a notification is sent. This method makes it far easier to communicate about project-related inquiries.
	\end{itemize}

	\subsection{Testing Tools}

	The special makefile discussed previously utilizes a phenomenon of C++ to perform the necessary steps. First, it places \textit{all} source files into a dedicated folder, distinguishing between program files and test files. This is an absolutely necessary step, as there is an important relationship between \textit{source} and \textit{test} classes. See the diagram below:

	\bigskip
	\bigskip
	\bigskip

	% Venn-diagram
	\centering
	\begin{tikzpicture}[fill=white]
		% left hand
		\scope
		\clip (1,0) circle (1);
		\endscope

		% right hand
		\scope
		\clip (0,0) circle (1);
		\endscope

		% outline
		\draw 	(-1,0) circle (2) (-4,1)  node [text=black,above] {$Source$}
		 		(1,0) circle (2) (4,1)  node [text=black,above] {$Test$};
	\end{tikzpicture}
	\flushleft

	\bigskip
	\bigskip

	As the diagram above depicts, there are classes shared between both final programs. The vast majority of classes fall in the center, required by both the final project and its testing component. The files required by the test which are not required by the source are, obviously, testing-related files. These are the files that contain the test case implementations. At the time of writing, there is actually only one file required by source that is not required by the test, and that is the source program entry (i.e. the file that contains the main() method).

	\bigskip

	The entire procedure of file collection, compilation, and separate linking is handled by the makefile, and is triggered by the "make" command. Then, simply running Test.exe will fire off all of the pre-written tests.

	\bigskip

	There is a plan to implement a python script on the GitLab pipeline that will cause the build to fail if any of the tests do not pass. At this time of writing this is not yet implemented, but note will be made when it does. It should be noted that if a build fails, the pipeline not only reports the failure, but also logs where the failure happened, down to the specific test case. This will hopefully make debugging a more pleasant experience later on.

	\subsection{Testing Schedule}
		
	See Gantt Chart at the following url ... TODO

\newpage
\section{System Test Description}
	
	\subsection{Tests for Functional Requirements}

		\subsubsection{Area of Testing1}
				
		\paragraph{Title for Test}

		\begin{enumerate}

			\item{test-id1\\}

			Type: Functional, Dynamic, Manual, Static etc.
								
			Initial State: 
								
			Input: 
								
			Output: 
								
			How test will be performed: 
								
			\item{test-id2\\}

			Type: Functional, Dynamic, Manual, Static etc.
								
			Initial State: 
								
			Input: 
								
			Output: 
								
			How test will be performed: 

		\end{enumerate}

	\subsubsection{Area of Testing2}

	...

	\subsection{Tests for Nonfunctional Requirements}

	\subsubsection{Area of Testing1}
			
		\paragraph{Title for Test}

		\begin{enumerate}

			\item{test-id1\\}

			Type: 
								
			Initial State: 
								
			Input/Condition: 
								
			Output/Result: 
								
			How test will be performed: 
								
			\item{test-id2\\}

			Type: Functional, Dynamic, Manual, Static etc.
								
			Initial State: 
								
			Input: 
								
			Output: 
								
			How test will be performed: 

		\end{enumerate}

	\subsubsection{Area of Testing2}
	...

\newpage
\section{Tests for Proof of Concept}

	\subsection{Area of Testing1}
				
		\paragraph{Title for Test}

		\begin{enumerate}

		\item{test-id1\\}

		Type: Functional, Dynamic, Manual, Static etc.
							
		Initial State: 
							
		Input: 
							
		Output: 
							
		How test will be performed: 
							
		\item{test-id2\\}

		Type: Functional, Dynamic, Manual, Static etc.
							
		Initial State: 
							
		Input: 
							
		Output: 
							
		How test will be performed: 

		\end{enumerate}

	\subsection{Area of Testing2}

	...

\newpage
\section{Comparison to Existing Implementation}	

	
\newpage
\section{Unit Testing Plan}
	
	After examining the boost library's utilities for unit testing, we have decided we will not use a unit testing framework for testing the product. We concluded that adding a framework would not make the work significantly easier, while reducing our flexibility and adding installation difficulties.
	
	\subsection{Unit testing of internal functions}
		Internal functions in the product will be unit tested. This will be reserved for more complex functions so as to not waste development time unnecessarily. The following are examples of internal functions that are good candidates for unit testing:
		\begin{itemize}
			\item The dungeon generation functions. The work of generating the dungeon is complex, but it is also easy to automate verification of dungeon properties such as a correct number of rooms, connectness, compliance with formulas for item generation, presence or absence of certain key features such as the stairs connecting levels or the Amulet of Yendor in the final level.
			\item The keyboard input functions. As libtcod provides a Key struct which models keyboard input, we can mock/automate these functions. They are fairly complex, and since they return a pointer to the next desired state (similar to a finite state machine) we can easily verify their behavior.
			\item Some of the item activation functions. For example it could be verified that when the player drank a potion of healing their health increased (if it was not at its maximum), when a scroll of magic-mapping is read the level was revealed, or that a scroll of identification reveals the nature of an item.
		\end{itemize}

	\subsection{Unit testing of output files}
		There is only one output file for the product, the high score file, which stores the scores in a csv format. The production and reading of this file can be unit-tested by verifying its contents after writing to it, and by providing a testing version of the file with known contents and verifying the function reads them correctly.

% \bibliographystyle{plainnat}

% \bibliography{SRS}

\newpage
\section{Appendix}

	This is where you can place additional information.

	\subsection{Symbolic Parameters}

		\begin{table}[h!]
			\centering
			\caption{\textbf{Symbolic Parameter Table}}
			\label{symbolicParameters}
			\bigskip
			\def\arraystretch{1.6}


			\begin{tabular}{| c | c |}
				\bottomrule
				\textbf{Parameter} & \textbf{Value} \\
				\hline
				FINAL\_LEVEL & 26 \\
				WIDTH\_RESOLUTION & 1280 \\
				HEIGHT\_RESOLUTION & 400 \\
				VIEW\_DISTANCE & 2 \\
				START\_LEVEL & 1 \\
				MINIMUM\_ENTERTAINMENT\_TIME & 20 \\
				MINIMUM\_RESPONSE\_SPEED & 30 \\
				HIGH\_SCORE\_CAPACITY & 15 \\
				LUMINOSITY\_DELTA & 0.5 \\
				\toprule
			\end{tabular}
		\end{table}

\newpage
\subsection{Usability Survey Questions?}

	\begin{itemize}
		\item Is there any game feature you were unable to figure out how to utilize?
		\item How helpful was the help screen for you?
		\item Was there anything going on in the game that the interface failed to make clear to you or deceived you about?
		\item What common UI interactions did you find particularly lengthy?
		\item What aspects of the interface did you find unintuitive?
		\item How responsive was the interface?
		\item How easy was it to see everything that was going on?
		\item How effective are the graphics/symbols?
		\item Would an alternative input device such as a mouse make interacting with the interface easier for you?
	\end{itemize}

\end{document}
