\documentclass[12pt, titlepage]{article}

\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{hyperref}
\usepackage{tikz}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=red,
    urlcolor=blue
}
%\usepackage[round]{natbib}

\title{SE 3XA3: Test Plan\\Rogue Reborn}

\author{Team \#6, Team Rogue++\\\\
	\begin{tabular} {l r}
		Ian Prins & prinsij \\
		Mikhail Andrenkov & andrem5 \\
		Or Almog  & almogo
	\end{tabular}
}

\date{Due Monday, October 31\textsuperscript{th}, 2016}

\input{../Comments}

\begin{document}

\maketitle

\pagenumbering{roman}
\tableofcontents
\listoftables
\listoffigures

\begin{table}[bp]
\caption{\bf Revision History}
\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
\toprule {\bf Date} & {\bf Version} & {\bf Notes}\\
\midrule
10/21/16 & 0.1 & Initial Setup\\
10/24/16 & 0.2 & Add Unit Testing and Usability Survey \\
\bottomrule
\end{tabularx}
\end{table}

\newpage

\pagenumbering{arabic}

This document ...

\section{General Information}

	\subsection{Purpose}

	\subsection{Scope}

	\subsection{Acronyms, Abbreviations, and Symbols}
		
		\begin{table}[hbp]
		\caption{\textbf{Table of Abbreviations}} \label{Table}

		\begin{tabularx}{\textwidth}{p{3cm}X}
			\toprule
			\textbf{Abbreviation} & \textbf{Definition} \\
			\midrule
			Abbreviation1 & Definition1\\
			Abbreviation2 & Definition2\\
			\bottomrule
		\end{tabularx}

		\end{table}

			\begin{table}[!htbp]
				\caption{\textbf{Table of Definitions}} \label{Table}

				\begin{tabularx}{\textwidth}{p{3cm}X}
				\toprule
				\textbf{Term} & \textbf{Definition}\\
				\midrule
				Term1 & Definition1\\
				Term2 & Definition2\\
				\bottomrule
			\end{tabularx}

		\end{table}	

	\subsection{Overview of Document}

\section{Plan}
		
	\subsection{Software Description}

	Initially, the plan for testing involved the usage of a pre-made testing system called Boost. Boost has industry renown and is very well documented. The drawback to using such a profound system is exactly its advantage - it is heavy, globally encompassing, and requires a lot of work to use properly. The Boost library is suitable for projects spanning years, with dedicated testing teams. This is not the present situation. With hardly over a month until the completion of the project, starting to use Boost would be most unwise.\\

	Instead, an alternative solution has been proposed and implemented. Native test cases can be written in C++ to do exactly that which is required. The details of this implementation will be explained in the parts to follow.

	\subsection{Test Team}

	All members of the team will take part in the testing procedure. While Mikhail was given the title of project manager, and Ian C++ expert, Ori was assigned the role of testing expert. Testing will be monitored by Ori, but of course every member of the team will contribute to the testing facilities. It would be desirable for the team member who wrote class $C$ to write the unit tests for this class. Due to the dependency-tree-like structure of the project's design, there will be cases where a unit test for one class encompasses a partial system test for another one. This can be extrapolated from the class inheritance diagram.

	\subsection{Automated Testing Approach}

	We have made a very large attempt at automating whatever we could for this project. In the real world, any task that \textit{can} be automated, is automated. The steps we have taken are as follows:

	\begin{itemize}
		\item Set up a GitLab pipeline for the project. The pipeline is programmed to run a series of commands on an external VPS whenever a push is made to the git repository. Each run is documented and its history may be accessed.
		\item Write a special makefile that outputs 2 executables: the first being the actual project, and the second the project's tests. The details will be delved into in the following sub-section.
		\item The team's primary method of communication is Slack, a cross-platform, programmer-friendly chat interface. We hooked up the GitLab project repository to the Slack channel such that whenever a push is made or an issue addressed, a notification is sent. This method makes it far easier to communicate about project-related inquiries.
	\end{itemize}

	\subsection{Testing Tools}

	The special makefile discussed previously utilizes a phenomenon of C++ to perform the necessary steps. First, it places \textit{all} source files into a dedicated folder, distinguishing between program files and test files. This is an absolutely necessary step, as there is an important relationship between \textit{source} and \textit{test} classes. See the diagram below:

	\bigskip
	\bigskip
	\bigskip

	% Venn-diagram
	\centering
	\begin{tikzpicture}[fill=white]
		% left hand
		\scope
		\clip (1,0) circle (1);
		\endscope

		% right hand
		\scope
		\clip (0,0) circle (1);
		\endscope

		% outline
		\draw 	(-1,0) circle (2) (-4,1)  node [text=black,above] {$Source$}
		 		(1,0) circle (2) (4,1)  node [text=black,above] {$Test$};
	\end{tikzpicture}
	\flushleft

	\bigskip
	\bigskip

	As the diagram above depicts, there are classes shared between both final programs. The vast majority of classes fall in the center, required by both the final project and its testing component. The files required by the test which are not required by the source are, obviously, testing-related files. These are the files that contain the test case implementations. The files required by the source which are not required by the test are 

	\subsection{Testing Schedule}
		
	See Gantt Chart at the following url ...

\section{System Test Description}
	
	\subsection{Tests for Functional Requirements}

		\subsubsection{Area of Testing1}
				
		\paragraph{Title for Test}

		\begin{enumerate}

			\item{test-id1\\}

			Type: Functional, Dynamic, Manual, Static etc.
								
			Initial State: 
								
			Input: 
								
			Output: 
								
			How test will be performed: 
								
			\item{test-id2\\}

			Type: Functional, Dynamic, Manual, Static etc.
								
			Initial State: 
								
			Input: 
								
			Output: 
								
			How test will be performed: 

		\end{enumerate}

	\subsubsection{Area of Testing2}

	...

	\subsection{Tests for Nonfunctional Requirements}

	\subsubsection{Area of Testing1}
			
		\paragraph{Title for Test}

		\begin{enumerate}

			\item{test-id1\\}

			Type: 
								
			Initial State: 
								
			Input/Condition: 
								
			Output/Result: 
								
			How test will be performed: 
								
			\item{test-id2\\}

			Type: Functional, Dynamic, Manual, Static etc.
								
			Initial State: 
								
			Input: 
								
			Output: 
								
			How test will be performed: 

		\end{enumerate}

	\subsubsection{Area of Testing2}

...

\section{Tests for Proof of Concept}

	\subsection{Area of Testing1}
				
		\paragraph{Title for Test}

		\begin{enumerate}

		\item{test-id1\\}

		Type: Functional, Dynamic, Manual, Static etc.
							
		Initial State: 
							
		Input: 
							
		Output: 
							
		How test will be performed: 
							
		\item{test-id2\\}

		Type: Functional, Dynamic, Manual, Static etc.
							
		Initial State: 
							
		Input: 
							
		Output: 
							
		How test will be performed: 

		\end{enumerate}

	\subsection{Area of Testing2}

	...

	
\section{Comparison to Existing Implementation}	
				
\section{Unit Testing Plan}
	
	After examining the boost library's utilities for unit testing, we have decided we will not use a unit testing framework for testing the product. We concluded that adding a framework would not make the work significantly easier, while reducing our flexibility and adding installation difficulties.
	
	\subsection{Unit testing of internal functions}
		Internal functions in the product will be unit tested. This will be reserved for more complex functions so as to not waste development time unnecessarily. The following are examples of internal functions that are good candidates for unit testing:
		\begin{itemize}
			\item The dungeon generation functions. The work of generating the dungeon is complex, but it is also easy to automate verification of dungeon properties such as a correct number of rooms, connectness, compliance with formulas for item generation, presence or absence of certain key features such as the stairs connecting levels or the Amulet of Yendor in the final level.
			\item The keyboard input functions. As libtcod provides a Key struct which models keyboard input, we can mock/automate these functions. They are fairly complex, and since they return a pointer to the next desired state (similar to a finite state machine) we can easily verify their behavior.
			\item Some of the item activation functions. For example it could be verified that when the player drank a potion of healing their health increased (if it was not at its maximum), when a scroll of magic-mapping is read the level was revealed, or that a scroll of identification reveals the nature of an item.
		\end{itemize}

	\subsection{Unit testing of output files}
		There is only one output file for the product, the high score file, which stores the scores in a csv format. The production and reading of this file can be unit-tested by verifying its contents after writing to it, and by providing a testing version of the file with known contents and verifying the function reads them correctly.

% \bibliographystyle{plainnat}

% \bibliography{SRS}

\newpage

\section{Appendix}

This is where you can place additional information.

\subsection{Symbolic Parameters}

	\begin{table}[h!]
		\centering
		\caption{\textbf{Symbolic Parameter Table}}
		\label{symbolicParameters}
		\bigskip
		\def\arraystretch{1.6}


		\begin{tabular}{| c | c |}
			\bottomrule
			\textbf{Parameter} & \textbf{Value} \\
			\hline
			FINAL\_LEVEL & 26 \\
			WIDTH\_RESOLUTION & 1280 \\
			HEIGHT\_RESOLUTION & 400 \\
			VIEW\_DISTANCE & 2 \\
			START\_LEVEL & 1 \\
			MINIMUM\_ENTERTAINMENT\_TIME & 20 \\
			MINIMUM\_RESPONSE\_SPEED & 30 \\
			HIGH\_SCORE\_CAPACITY & 15 \\
			LUMINOSITY\_DELTA & 0.5 \\
			\toprule
		\end{tabular}
	\end{table}


\subsection{Usability Survey Questions?}

	\begin{itemize}
		\item Is there any game feature you were unable to figure out how to utilize?
		\item How helpful was the help screen for you?
		\item Was there anything going on in the game that the interface failed to make clear to you or deceived you about?
		\item What common UI interactions did you find particularly lengthy?
		\item What aspects of the interface did you find unintuitive?
		\item How responsive was the interface?
		\item How easy was it to see everything that was going on?
		\item How effective are the graphics/symbols?
		\item Would an alternative input device such as a mouse make interacting with the interface easier for you?
	\end{itemize}

\end{document}
